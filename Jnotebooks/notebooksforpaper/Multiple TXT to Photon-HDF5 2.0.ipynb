{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting raw .txt files from labview to fretbursts compatible HDF5 files\n",
    "\n",
    "This notebook will convert multiple TXT files into a single combined HDF5 file, useful if you want to analyse multiple acquisitions as if they were all part of the same run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import phconvert as phc\n",
    "import csv\n",
    "phc.__version__\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by naming the first file and reading it in. You will need to give the length of the individual acquisitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['definitiveset/1c1.txt', 'definitiveset/1c2.txt']\n"
     ]
    }
   ],
   "source": [
    "T = 180000000000 #this is the length of EACH experiment\n",
    "filenames = [\"definitiveset/1c1.txt\", \n",
    "            \"definitiveset/1c2.txt\"]\n",
    "savename = 'definitiveset/1cx.hdf5'\n",
    "print(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        7295        76304       113235 ... 179991641539 179991642830\n",
      " 179991651103]\n",
      "definitiveset/1c1.txt done\n",
      "[180000301012 180000362888 180000543792 ... 359990845480 359990853519\n",
      " 359990933468]\n",
      "definitiveset/1c2.txt done\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "detectors = np.empty([0], dtype=int)\n",
    "timestamps = np.empty([0], dtype=int)\n",
    "files = 0\n",
    "\n",
    "for file in filenames:\n",
    "    with open(file) as inf:\n",
    "        reader = csv.reader(inf, delimiter=\"\t\")\n",
    "        ftimestamps = list(zip(*reader))[0]\n",
    "    \n",
    "    with open(file) as inf:\n",
    "        reader = csv.reader(inf, delimiter=\"\t\")\n",
    "        fdetectors = list(zip(*reader))[1]\n",
    "\n",
    "    fdetectors = np.asarray(fdetectors)\n",
    "    ftimestamps = np.asarray(ftimestamps)\n",
    "\n",
    "    ftimestamps = np.int64(ftimestamps)\n",
    "    fdetectors = np.uint8(fdetectors)\n",
    "    #the following code is necessary because sometimes there are a couple of photons\n",
    "    #counted after the stated end of the experiment\n",
    "    bleed = 0\n",
    "    for x in reversed(ftimestamps): #this is a reversed search because it's looking for numbers at the end, and if it starts at the beginning it will have to go through several million to get there\n",
    "        if x > T :\n",
    "            bleed +=1\n",
    "        else:\n",
    "            break\n",
    "    ftimestamps = np.resize(ftimestamps, ftimestamps.size - bleed)\n",
    "    fdetectors = np.resize(fdetectors, fdetectors.size - bleed)\n",
    "    #This moves along the timestamps by which experiment it is\n",
    "    ftimestamps = ftimestamps + (files * T)\n",
    "    files = files + 1\n",
    "    print(ftimestamps)\n",
    "    timestamps = np.concatenate([timestamps, ftimestamps])\n",
    "    detectors = np.concatenate([detectors, fdetectors])\n",
    "    print(file + \" done\")\n",
    "    \n",
    "timestamps = np.int64(timestamps)\n",
    "detectors = np.uint8(detectors)\n",
    "print(\"all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some metadata\n",
    "\n",
    "Put information between quotation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "description = '[insert description of experiment]'\n",
    "\n",
    "author = 'Benjamin Ambrose'\n",
    "author_affiliation = 'University of Sheffield'\n",
    "\n",
    "sample_name = 'describe the sample here'\n",
    "buffer_name = 'describe the buffer here'\n",
    "dye_names = 'Atto550, ATTO647N'   # Comma separates names of fluorophores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Photon-HDF5 data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamps_unit = 10e-9  # 10 ns, units are always S.I.\n",
    "photon_data = dict(\n",
    "    timestamps=timestamps,\n",
    "    detectors=detectors,\n",
    "    timestamps_specs={'timestamps_unit': timestamps_unit})\n",
    "setup = dict(\n",
    "    ## Mandatory fields\n",
    "    num_pixels = 2,                   # using 2 detectors\n",
    "    num_spots = 1,                    # a single confoca excitation\n",
    "    num_spectral_ch = 2,              # donor and acceptor detection \n",
    "    num_polarization_ch = 1,          # no polarization selection \n",
    "    num_split_ch = 1,                 # no beam splitter\n",
    "    modulated_excitation = False,     # CW excitation, no modulation \n",
    "    excitation_alternated = [True],  # CW excitation, no modulation \n",
    "    lifetime = False,                 # no TCSPC in detection    \n",
    "    ## Optional fields\n",
    "    excitation_wavelengths = [515e-9, 638e-9],         # List of excitation wavelenghts\n",
    "    excitation_cw = [True],                    # List of booleans, True if wavelength is CW\n",
    "    detection_wavelengths = [580e-9, 690e-9],  # Nominal center wavelength \n",
    "                                               # each for detection ch\n",
    ")\n",
    "identity = dict(\n",
    "    author=author,\n",
    "    author_affiliation=author_affiliation)\n",
    "measurement_specs = dict(\n",
    "    measurement_type = 'smFRET-usALEX',\n",
    "    detectors_specs = {'spectral_ch1': [0],  # list of donor's detector IDs\n",
    "                       'spectral_ch2': [1]},  # list of acceptor's detector IDs,\n",
    "    alex_period = 10000,\n",
    "    )\n",
    "photon_data['measurement_specs'] = measurement_specs\n",
    "\n",
    "data = dict(\n",
    "    description=description,\n",
    "    photon_data = photon_data,\n",
    "    setup=setup,\n",
    "    identity=identity,\n",
    ")\n",
    "phc.hdf5.save_photon_hdf5(data, h5_fname=savename, overwrite=True)\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
