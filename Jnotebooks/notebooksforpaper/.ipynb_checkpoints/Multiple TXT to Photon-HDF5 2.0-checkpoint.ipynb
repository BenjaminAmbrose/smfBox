{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting raw .txt files from labview to fretbursts compatible HDF5 files\n",
    "\n",
    "This notebook will convert multiple TXT files into a single combined HDF5 file, useful if you want to analyse multiple acquisitions as if they were all part of the same run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import phconvert as phc\n",
    "import csv\n",
    "phc.__version__\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by naming the first file and reading it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['definitiveset/1c1.txt', 'definitiveset/1c2.txt']\n"
     ]
    }
   ],
   "source": [
    "T = 180000000000 #this is the length of EACH experiment\n",
    "filenames = [\"definitiveset/1c1.txt\", \n",
    "            \"definitiveset/1c2.txt\"]\n",
    "savename = 'definitiveset/1cx.hdf5'\n",
    "print(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        7295        76304       113235 ... 179991641539 179991642830\n",
      " 179991651103]\n",
      "[180000301012 180000362888 180000543792 ... 359990845480 359990853519\n",
      " 359990933468]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "detectors = np.empty([0], dtype=int)\n",
    "timestamps = np.empty([0], dtype=int)\n",
    "files = 0\n",
    "\n",
    "for file in filenames:\n",
    "    with open(file) as inf:\n",
    "        reader = csv.reader(inf, delimiter=\"\t\")\n",
    "        ftimestamps = list(zip(*reader))[0]\n",
    "    \n",
    "    with open(file) as inf:\n",
    "        reader = csv.reader(inf, delimiter=\"\t\")\n",
    "        fdetectors = list(zip(*reader))[1]\n",
    "\n",
    "    fdetectors = np.asarray(fdetectors)\n",
    "    ftimestamps = np.asarray(ftimestamps)\n",
    "\n",
    "    ftimestamps = np.int64(ftimestamps)\n",
    "    fdetectors = np.uint8(fdetectors)\n",
    "    #the following code is necessary because sometimes there are a couple of photons\n",
    "    #counted after the stated end of the experiment, I don't know why, my degree\n",
    "    #was in biology\n",
    "    bleed = 0\n",
    "    for x in reversed(ftimestamps): #this is a reversed search because it's looking for numbers at the end, and if it starts at the beginning it will have to go through several million to get there\n",
    "        if x > T :\n",
    "            bleed +=1\n",
    "        else:\n",
    "            break\n",
    "    ftimestamps = np.resize(ftimestamps, ftimestamps.size - bleed)\n",
    "    fdetectors = np.resize(fdetectors, fdetectors.size - bleed)\n",
    "    #This moves along the timestamps by which experiment it is\n",
    "    ftimestamps = ftimestamps + (files * T)\n",
    "    files = files + 1\n",
    "    print(ftimestamps)\n",
    "    timestamps = np.concatenate([timestamps, ftimestamps])\n",
    "    detectors = np.concatenate([detectors, fdetectors])\n",
    "    \n",
    "    \n",
    "timestamps = np.int64(timestamps)\n",
    "detectors = np.uint8(detectors)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create some metadata\n",
    "\n",
    "Put information between quotation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "description = 'blah blah blah meta data'\n",
    "\n",
    "author = 'Author Name'\n",
    "author_affiliation = 'Name of Research Institution'\n",
    "\n",
    "sample_name = 'describe the sample here'\n",
    "buffer_name = 'describe the buffer here'\n",
    "dye_names = 'Cy3B, ATTO647N'   # Comma separates names of fluorophores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Photon-HDF5 data structure\n",
    "\n",
    "In this section we create all the mandatory and non mandatory groups.\n",
    "Not all of the are required to save a valid Photon-HDF5 file\n",
    "(see example in section 4).\n",
    "\n",
    "## 3.1 `photon_data` group\n",
    "\n",
    "Contains arrays of photon-data: timestamps, detectors, nanotimes, etc...\n",
    "\n",
    "Our timestamps are in nanoseconds so we put \"10e9\"\n",
    "\n",
    "*See [photon_data group reference](http://photon-hdf5.readthedocs.org/en/latest/phdata.html#photon-data-group)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamps_unit = 10e-9\n",
    "photon_data = dict(\n",
    "    timestamps=timestamps,\n",
    "    detectors=detectors,\n",
    "    timestamps_specs={'timestamps_unit': timestamps_unit})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 `setup` group\n",
    "\n",
    "The `/setup` group contains information about the measurement setup. \n",
    "\n",
    "*See [setup group reference](http://photon-hdf5.readthedocs.org/en/latest/phdata.html#setup-group).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup = dict(\n",
    "    ## Mandatory fields\n",
    "    num_pixels = 2,                   # using 2 detectors\n",
    "    num_spots = 1,                    # a single confoca excitation\n",
    "    num_spectral_ch = 2,              # donor and acceptor detection \n",
    "    num_polarization_ch = 1,          # no polarization selection \n",
    "    num_split_ch = 1,                 # no beam splitter\n",
    "    modulated_excitation = False,     # CW excitation, no modulation \n",
    "    excitation_alternated = [True],  # CW excitation, no modulation \n",
    "    lifetime = False,                 # no TCSPC in detection\n",
    "    \n",
    "    ## Optional fields\n",
    "    excitation_wavelengths = [532e-9, 635e-9],         # List of excitation wavelenghts\n",
    "    excitation_cw = [True],                    # List of booleans, True if wavelength is CW\n",
    "    detection_wavelengths = [580e-9, 640e-9],  # Nominal center wavelength \n",
    "                                               # each for detection ch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 `provenance` group\n",
    "\n",
    "Non-mandatory group containing info about the original file \n",
    "prior to Photon-HDF5 conversion. If some information is not \n",
    "available the relative field may be omitted.\n",
    "\n",
    "If you provide the file path for the original file before conversion then this will be packed into the HDF5\n",
    "\n",
    "*See [provenance group documentation](http://photon-hdf5.readthedocs.org/en/latest/phdata.html#provenance-group).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "provenance = dict(\n",
    "    filename='original_data_file.dat', \n",
    "    software='Acquisition Software Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 `identity` group\n",
    "\n",
    "Non-mandatory group containing info about information \n",
    "this specific Photon-HDF5 file.\n",
    "\n",
    "*See [identity group documentation](http://photon-hdf5.readthedocs.org/en/latest/phdata.html#identity-group).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity = dict(\n",
    "    author=author,\n",
    "    author_affiliation=author_affiliation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 `measurement_specs` group\n",
    "\n",
    "The optional /photon_data/measurement_specs group contains \n",
    "additional information allowing unambiguous interpretation \n",
    "of the data for each specific type of measurement.\n",
    "\n",
    "*See [measurement_specs group documentation](http://photon-hdf5.readthedocs.org/en/latest/phdata.html#measurement-specs).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "measurement_specs = dict(\n",
    "    measurement_type = 'smFRET-usALEX',\n",
    "    detectors_specs = {'spectral_ch1': [0],  # list of donor's detector IDs\n",
    "                       'spectral_ch2': [1]},  # list of acceptor's detector IDs,\n",
    "    alex_period = 10000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save Photon-HDF5 files\n",
    "\n",
    "To save a file we need to join together the root fields and group \n",
    "in a single dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "photon_data['measurement_specs'] = measurement_specs\n",
    "\n",
    "data = dict(\n",
    "    description=description,\n",
    "    photon_data = photon_data,\n",
    "    setup=setup,\n",
    "    identity=identity,\n",
    "    provenance=provenance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not locate original file 'original_data_file.dat'.\n",
      "         File info in provenance group will not be added.\n",
      "\n",
      "Saving: definitiveset/1cx.hdf5\n"
     ]
    }
   ],
   "source": [
    "phc.hdf5.save_photon_hdf5(data, h5_fname=savename, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** a user of this file can correctly interpret the data\n",
    "> reading that the measurement type is 'smFRET' (meaning smFRET with single laser\n",
    "> excitation and 2-colors detection) and the IDs of donor and acceptor detectors\n",
    "> (from `detectors_specs/spectral_ch1` and `spectral_ch2` respectively)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
